# NlpProject
This project focuses on building and implementing advanced text summarization techniques to process large-scale textual data.
Firstly, we are selecting the most relevant sentences or phrases from the original text.
Then, we are generating new sentences that convey the core meaning of the original content.

The model was fine-tuned using the Gamma 2b architecture with adjusted parameters for Rank (r) and Alpha to optimize performance. Tools like Python, TensorFlow, and Jupyter Notebook were extensively used for model training, inference, and evaluation.

Key challenges included handling large datasets and optimizing GPU resources during inference. The project demonstrates expertise in Natural Language Processing (NLP) and data preprocessing techniques.

Technologies & Tools:

Languages: Python
Frameworks: TensorFlow, scikit-learn
Techniques: Machine Learning, NLP, Extractive & Abstractive Summarization
Tools: Jupyter Notebook, GPUs for model training
